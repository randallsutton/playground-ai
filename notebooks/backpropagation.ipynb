{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572ad5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "input_features = np.array([0.5, 0.1, -0.2])               # (3,)\n",
    "expected_output = 0.6                                     # scalar\n",
    "learning_rate = 0.5                                       # scalar\n",
    "weights_from_input_to_hidden = np.array([[0.5, -0.6],     # (3, 2) - 3 inputs to 2 hidden\n",
    "                                         [0.1, -0.2],\n",
    "                                         [0.1, 0.7]])\n",
    "weights_from_hidden_to_output = np.array([0.1, -0.3])     # (2,) - 2 hidden to 1 output\n",
    "\n",
    "### Forward pass\n",
    "\n",
    "# Compute activations by passing weighted sums through sigmoid\n",
    "hidden_layer_activation = sigmoid(np.dot(input_features, weights_from_input_to_hidden))  # (2,)\n",
    "output_layer_activation = sigmoid(np.dot(hidden_layer_activation, weights_from_hidden_to_output))  # scalar\n",
    "\n",
    "### Backwards pass\n",
    "\n",
    "## Output layer\n",
    "\n",
    "# Error: difference between expected and actual output\n",
    "output_layer_error = expected_output - output_layer_activation  # scalar\n",
    "# Gradient: sigmoid derivative for the output neuron (how responsive is this neuron?)\n",
    "output_layer_gradient = output_layer_activation * (1 - output_layer_activation)  # scalar\n",
    "# Scaled error: how much should this neuron change? (how wrong × how responsive)\n",
    "output_layer_scaled_error = output_layer_error * output_layer_gradient  # scalar\n",
    "\n",
    "## Hidden layer\n",
    "\n",
    "# Error: blame assigned to each hidden neuron based on its connection strength\n",
    "hidden_layer_error = output_layer_scaled_error * weights_from_hidden_to_output  # (2,)\n",
    "# Gradient: sigmoid derivative for each hidden neuron (how responsive is this neuron?)\n",
    "hidden_layer_gradient = hidden_layer_activation * (1 - hidden_layer_activation)  # (2,)\n",
    "# Scaled error: how much should each hidden neuron change? (how wrong × how responsive)\n",
    "hidden_layer_scaled_error = hidden_layer_error * hidden_layer_gradient  # (2,)\n",
    "\n",
    "# Weight updates: how much should it change × how much did this input contribute x learning rate to reduce the delta\n",
    "delta_weights_from_hidden_to_output = learning_rate * output_layer_scaled_error * hidden_layer_activation  # (2,)\n",
    "delta_weights_from_input_to_hidden = learning_rate * np.outer(input_features, hidden_layer_scaled_error)  # (3, 2)\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_weights_from_hidden_to_output)\n",
    "\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_weights_from_input_to_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground-ai (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
